{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac9b5b57",
   "metadata": {},
   "source": [
    "# 03 - Modelo SVM (estilo completo, siguiendo pipeline)\n",
    "\n",
    "Notebook preparado para usar el archivo `train_preprocesado_completo.csv` generado por el pipeline `02 - preprocesado.ipynb`. Usa `RENDIMIENTO_GLOBAL` como target. Este notebook está diseñado para verse tan completo como el de tu compañero: secciones extensas, tablas, gráficos y exportación de resultados.\n",
    "\n",
    "**Recomendación:** ejecuta antes la celda del notebook 02 para generar `train_preprocesado_completo.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6561c056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import pickle\n",
    "\n",
    "# Para que las figuras se vean en el notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026e691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Cargar datos preprocesados\n",
    "DATA_PATH = 'train_preprocesado_completo.csv'\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(f\"No se encontró {DATA_PATH}. Ejecuta el notebook 02 para generarlo o coloca el archivo en la carpeta.\")\n",
    "\n",
    "print('Cargando:', DATA_PATH)\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print('Dimensiones:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba0f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Información y primeras tablas\n",
    "print('Columnas:', df.columns.tolist())\n",
    "print('\\nTipos de datos:')\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "print('\\nMuestra de estadísticas (numéricas):')\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89df1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Análisis del target `RENDIMIENTO_GLOBAL`\n",
    "target = 'RENDIMIENTO_GLOBAL'\n",
    "if target not in df.columns:\n",
    "    raise KeyError(f\"La columna target '{target}' no está en el dataset. Columnas disponibles: {df.columns.tolist()}\")\n",
    "\n",
    "print('Valores únicos del target:', df[target].unique())\n",
    "print('\\nDistribución del target:')\n",
    "print(df[target].value_counts(normalize=True))\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(data=df, x=target)\n",
    "plt.title('Distribución de RENDIMIENTO_GLOBAL')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716a94b1",
   "metadata": {},
   "source": [
    "## Archivos individuales generados por el pipeline\n",
    "El pipeline 02 genera CSV individuales por cada variable categórica (si `generar_csv_individual=True`). A continuación listamos archivos `trainpreprocesado{col}.csv` que existan en la carpeta para que puedas inspeccionarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86496661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "ind_files = sorted(glob.glob('trainpreprocesadopreprocesado*.csv') + glob.glob('trainpreprocesado*.csv') + glob.glob('train*preprocesado*.csv'))\n",
    "print('Archivos encontrados (algunos patrones):')\n",
    "for f in ind_files[:20]:\n",
    "    print('-', f)\n",
    "\n",
    "if not ind_files:\n",
    "    print('No se encontraron CSV individuales con patrón; esto es opcional y depende del pipeline.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdef62cc",
   "metadata": {},
   "source": [
    "## 4) Preparación de X e y\n",
    "Separamos la columna `ID` (si existe) y la columna objetivo `RENDIMIENTO_GLOBAL`. Además guardamos un `ID` para poder volver a unir predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faec1b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc = df.copy()\n",
    "ID_col = None\n",
    "if 'ID' in df_proc.columns:\n",
    "    ID_col = df_proc['ID']\n",
    "    df_proc = df_proc.drop(columns=['ID'])\n",
    "\n",
    "# Separar X,y\n",
    "X = df_proc.drop(columns=[target])\n",
    "y = df_proc[target]\n",
    "\n",
    "print('X shape:', X.shape)\n",
    "print('y shape:', y.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce3a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Estadísticas de variables numéricas y correlaciones (si aplica)\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print('Número de columnas numéricas:', len(num_cols))\n",
    "\n",
    "if len(num_cols) > 0:\n",
    "    display(X[num_cols].describe().T)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(X[num_cols].corr(), annot=False, cmap='RdBu', center=0)\n",
    "    plt.title('Mapa de correlación (numéricas)')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No se detectaron columnas numéricas.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fd4946",
   "metadata": {},
   "source": [
    "## 6) Split Train/Test\n",
    "Usamos `train_test_split` estratificado y mostramos tamaños y primeros registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc54c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print('Train:', X_train.shape, 'Test:', X_test.shape)\n",
    "\n",
    "# Mostrar primeras filas de train\n",
    "train_preview = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)\n",
    "train_preview.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d219a95c",
   "metadata": {},
   "source": [
    "## 7) Estandarización y Pipeline\n",
    "Para SVM es importante estandarizar las variables numéricas. Construimos un pipeline con `StandardScaler` + `SVC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc7ae8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc', SVC(probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'svc__C': [0.1, 1, 10],\n",
    "    'svc__gamma': ['scale', 'auto', 0.01],\n",
    "    'svc__kernel': ['rbf']\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print('Pipeline y grid listos. Ejecutando GridSearchCV...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe41f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipeline, param_grid, cv=cv, scoring='f1_weighted', n_jobs=-1, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print('Mejor score (CV):', grid.best_score_)\n",
    "print('Mejores parámetros:', grid.best_params_)\n",
    "\n",
    "best_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fff6a06",
   "metadata": {},
   "source": [
    "## 8) Evaluación en Test\n",
    "Mostramos métricas clásicas y matriz de confusión. Además calculamos ROC AUC si es binario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4767c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "y_acc = accuracy_score(y_test, y_pred)\n",
    "y_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print('Accuracy:', y_acc)\n",
    "print('F1 (weighted):', y_f1)\n",
    "print('\\nClassification report:\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion matrix:\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caa45ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de confusión - Test')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicho')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e41726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(y.unique()) == 2:\n",
    "    y_proba = best_model.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    print('ROC AUC:', auc)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0,1],[0,1],'--')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Problema multiclase: no se muestra ROC AUC automáticamente.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3924df1c",
   "metadata": {},
   "source": [
    "## 9) Guardar modelo y objetos\n",
    "Guardamos el modelo final y el scaler en la carpeta `outputs/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe6ebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('outputs', exist_ok=True)\n",
    "with open('outputs/modelo_03_SVM.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "# Guardar métricas\n",
    "metrics = {'accuracy': float(y_acc), 'f1_weighted': float(y_f1), 'best_params': grid.best_params_}\n",
    "import json\n",
    "with open('outputs/metrics_modelo_03_SVM.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print('Model y métricas guardados en outputs/.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590ab214",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nArchivos en outputs/')\n",
    "import glob\n",
    "for f in glob.glob('outputs/*'):\n",
    "    print('-', f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7debf6e",
   "metadata": {},
   "source": [
    "### Notas finales\n",
    "- Si quieres que el notebook use el pipeline 02 directamente, podríamos importar `preprocesar_pipeline` y generar el `train_preprocesado_completo.csv` desde aquí.\n",
    "- Si deseas que en vez de GridSearchCV usemos RandomizedSearchCV o ajustes de hiperparámetros más amplios, lo modifico.\n",
    "\n",
    "Listo — este notebook está preparado para ser visualmente largo, con tablas y gráficos, listo para presentación."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
